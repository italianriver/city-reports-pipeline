{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "645b487a-d44c-4d48-b990-a30c41ec1cff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import TimestampType\n",
    "from delta.tables import DeltaTable\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a075d110-61e2-4534-8b4c-77e8cb178cf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-5477239898229023>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mvars\u001B[39m \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39mjobs\u001B[38;5;241m.\u001B[39mtaskValues\u001B[38;5;241m.\u001B[39mget(taskKey\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbronze_task\u001B[39m\u001B[38;5;124m'\u001B[39m, key\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlayer_vars_key\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[1;32m      3\u001B[0m bronze_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mvars\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbronze_path\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
       "\u001B[1;32m      4\u001B[0m silver_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mvars\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msilver_path\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/dbutils.py:254\u001B[0m, in \u001B[0;36mDBUtils.JobsHandler.TaskValuesHandler.get\u001B[0;34m(self, taskKey, key, default, debugValue)\u001B[0m\n",
       "\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNotInJobContextException\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m exceptionClassName:\n",
       "\u001B[1;32m    253\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m debugValue \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m--> 254\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n",
       "\u001B[1;32m    255\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMust pass debugValue when calling get outside of a job context. debugValue cannot be None.\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
       "\u001B[1;32m    256\u001B[0m         ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    257\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m debugValue\n",
       "\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: Must pass debugValue when calling get outside of a job context. debugValue cannot be None."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "TypeError",
        "evalue": "Must pass debugValue when calling get outside of a job context. debugValue cannot be None."
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-5477239898229023>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mvars\u001B[39m \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39mjobs\u001B[38;5;241m.\u001B[39mtaskValues\u001B[38;5;241m.\u001B[39mget(taskKey\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbronze_task\u001B[39m\u001B[38;5;124m'\u001B[39m, key\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlayer_vars_key\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m bronze_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mvars\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbronze_path\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      4\u001B[0m silver_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mvars\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msilver_path\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/dbutils.py:254\u001B[0m, in \u001B[0;36mDBUtils.JobsHandler.TaskValuesHandler.get\u001B[0;34m(self, taskKey, key, default, debugValue)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNotInJobContextException\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m exceptionClassName:\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m debugValue \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 254\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    255\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMust pass debugValue when calling get outside of a job context. debugValue cannot be None.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    256\u001B[0m         ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    257\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m debugValue\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mTypeError\u001B[0m: Must pass debugValue when calling get outside of a job context. debugValue cannot be None."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vars = dbutils.jobs.taskValues.get(taskKey='bronze_task', key='layer_vars_key')\n",
    "\n",
    "# extracting required vars from dict\n",
    "bronze_reports = vars['bronze_reports']\n",
    "silver_reports = vars['silver_reports']\n",
    "silver_path = vars['silver_path']\n",
    "gold_path = vars['gold_path']\n",
    "gold_reports = vars['gold_reports']\n",
    "\n",
    "# static lookup table for geocoding\n",
    "coords_lookup_table = 'gemeente.lookup.coords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d37306c6-ca8e-4876-babd-ebb1688b059b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ingest bronze reports as streaming delta table, delta takes cares of incrremental loading\n",
    "df = spark.read.table(bronze_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcf905f6-10fb-487c-bbf2-d92a42034889",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# removing duplicate records\n",
    "df = df.dropDuplicates(['id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dcd459e-2b2a-4c09-8022-ed757a3fc86c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# validating records for null values\n",
    "null_counts = df.filter((F.col('street_name').isNull()) | (F.col('problem').isNull())).count()\n",
    "if null_counts > 0:\n",
    "    df = df.dropna(subset=['street_name','problem','id'])\n",
    "    print(f'Dropped {null_counts} records with null values')\n",
    "\n",
    "house_num_nulls = df.filter(F.col('house_number').isNull()).count()\n",
    "if house_num_nulls > 0:\n",
    "    df = df.withColumn('house_number', F.when(F.col('house_number').isNull(), F.lit(0)).otherwise(F.col('house_number')))\n",
    "    print(f'Changed {house_num_nulls} records with an invalid house number to 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f81da37d-dee9-44f6-9ac8-20e9673cbf31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# normalizing problem column (lowercase and trimming whitespace)\n",
    "df = df.withColumn('problem_norm',F.lower(F.trim(F.col('problem'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2ae84b4-3a7e-495c-8c31-5a0945aacd4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# unix time to readable format\n",
    "df = df.withColumn('reported_on',F.from_unixtime(F.col('report_date')).cast('timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "901b581c-7f44-469d-83e7-1e96ebe81e2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# adding new timestamp column to support SCD\n",
    "df = df.withColumn('status_updated_at',F.lit(None).cast('timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ca746d7-95f1-468c-be71-3c555209f339",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# preparation for SQL join for enrichment\n",
    "# loading df in temp view for SQL join\n",
    "df.createOrReplaceTempView('reports_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b98b238-9d54-4521-bd0f-128289e527ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # enriching the dateframe with lat and long coordinates using the static lookup table\n",
    "# # window function used to select best match for missing house numbers\n",
    "df_enriched = spark.sql(f'''\n",
    "          WITH enriched AS (\n",
    "            SELECT\n",
    "                l.id,\n",
    "                l.problem,\n",
    "                l.problem_norm,\n",
    "                l.street_name,\n",
    "                l.house_number,\n",
    "                l.reported_on,\n",
    "                r.postcode,\n",
    "                r.lon,\n",
    "                r.lat,\n",
    "                l.status,\n",
    "                l.status_updated_at,\n",
    "                ABS(r.huisnummer - l.house_number) AS distance,\n",
    "                ROW_NUMBER() OVER (\n",
    "                    PARTITION BY l.id\n",
    "                    ORDER BY ABS(r.huisnummer - l.house_number)\n",
    "                ) AS rn\n",
    "            FROM reports_view AS l\n",
    "            LEFT JOIN {coords_lookup_table} AS r\n",
    "                ON l.street_name = r.openbare_ruimte_naam\n",
    "        )\n",
    "        SELECT *\n",
    "        FROM enriched\n",
    "        WHERE rn = 1;\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf08fe00-4e16-41b3-98cc-bbf43b970c45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# selecting only interesting columns for silver table\n",
    "df_enriched = df_enriched.select(\n",
    "    'id',\n",
    "    'problem',\n",
    "    'problem_norm',\n",
    "    'street_name',\n",
    "    'house_number',\n",
    "    'reported_on',\n",
    "    'postcode',\n",
    "    'lon',\n",
    "    'lat',\n",
    "    'status',\n",
    "    'status_updated_at',\n",
    "    'distance'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "745dad3d-59ef-458c-8191-9b12bf4febc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MERGE new records to prevent duplicates in case of unexpected reprocessing of task\n",
    "# load existing records as DeltaTable, spark df does not support ACID\n",
    "# using overwrite mode for first table initiation\n",
    "\n",
    "if spark.catalog.tableExists(silver_reports):\n",
    "    print('Silver table exists → started merge')\n",
    "    silver_table = DeltaTable.forName(spark, silver_reports)\n",
    "    (\n",
    "        silver_table.alias('existing')\n",
    "        .merge(\n",
    "            df_enriched.alias('new'),     \n",
    "            'existing.id = new.id',          \n",
    "        )\n",
    "        .whenMatchedUpdateAll()\n",
    "        .whenNotMatchedInsertAll()\n",
    "        .execute()\n",
    "    )\n",
    "else:\n",
    "    print('Silver table does not exist → creating new table')\n",
    "    (df_enriched.write.mode('overwrite').format('delta').option('path', silver_path).saveAsTable(silver_reports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a3e96c4-b725-4a77-9bb2-f29847b6fb5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-5715372267379488>, line 5\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;28mvars\u001B[39m \u001B[38;5;241m=\u001B[39m {\n",
       "\u001B[1;32m      2\u001B[0m     \u001B[38;5;66;03m#'source_path':source_path,\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m     \u001B[38;5;66;03m#'bronze_path':bronze_path,\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m#'silver_path':silver_path,\u001B[39;00m\n",
       "\u001B[0;32m----> 5\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgold_path\u001B[39m\u001B[38;5;124m'\u001B[39m:gold_path,\n",
       "\u001B[1;32m      6\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msilver_reports\u001B[39m\u001B[38;5;124m'\u001B[39m:silver_reports,\n",
       "\u001B[1;32m      7\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgold_reports\u001B[39m\u001B[38;5;124m'\u001B[39m:gold_reports\n",
       "\u001B[1;32m      8\u001B[0m     \u001B[38;5;66;03m#'coords_lookup_table':'gemeente.lookup.coords'          # static lookup table managed through UC\u001B[39;00m\n",
       "\u001B[1;32m      9\u001B[0m }\n",
       "\u001B[1;32m     11\u001B[0m dbutils\u001B[38;5;241m.\u001B[39mjobs\u001B[38;5;241m.\u001B[39mtaskValues\u001B[38;5;241m.\u001B[39mset(key\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlayer_vars_key\u001B[39m\u001B[38;5;124m'\u001B[39m, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mvars\u001B[39m)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'gold_path' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'gold_path' is not defined"
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-5715372267379488>, line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mvars\u001B[39m \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;66;03m#'source_path':source_path,\u001B[39;00m\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;66;03m#'bronze_path':bronze_path,\u001B[39;00m\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m#'silver_path':silver_path,\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgold_path\u001B[39m\u001B[38;5;124m'\u001B[39m:gold_path,\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msilver_reports\u001B[39m\u001B[38;5;124m'\u001B[39m:silver_reports,\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgold_reports\u001B[39m\u001B[38;5;124m'\u001B[39m:gold_reports\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;66;03m#'coords_lookup_table':'gemeente.lookup.coords'          # static lookup table managed through UC\u001B[39;00m\n\u001B[1;32m      9\u001B[0m }\n\u001B[1;32m     11\u001B[0m dbutils\u001B[38;5;241m.\u001B[39mjobs\u001B[38;5;241m.\u001B[39mtaskValues\u001B[38;5;241m.\u001B[39mset(key\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlayer_vars_key\u001B[39m\u001B[38;5;124m'\u001B[39m, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mvars\u001B[39m)\n",
        "\u001B[0;31mNameError\u001B[0m: name 'gold_path' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ouput vars required for next notebook in job pipeline\n",
    "vars = {\n",
    "\n",
    "    'gold_path':gold_path,\n",
    "    'silver_reports':silver_reports,\n",
    "    'gold_reports':gold_reports\n",
    "}\n",
    "\n",
    "dbutils.jobs.taskValues.set(key='layer_vars_key', value=vars)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8530175208273831,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}